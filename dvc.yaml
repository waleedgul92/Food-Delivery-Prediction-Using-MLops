stages:
  data_ingestion:
    cmd: python src/data_ingestion.py
    deps:
      - src/data_ingestion.py
      # REMOVED: data/raw/dataset.csv is no longer a dep
    params:
      - base.random_state
      - data_split.test_size
      - data.s3_bucket      # ADDED: Script now depends on this param
      - data.s3_key         # ADDED: Script now depends on this param
      - data.interim_dir    # ADDED: Script needs this for output path
      - data.train_csv      # ADDED: Script needs this for output path
      - data.test_csv       # ADDED: Script needs this for output path
    outs:
      - data/interim

  data_processing:
    cmd: python src/data_process.py
    deps:
      - src/data_process.py
      - data/interim
    params:
      - base.random_state
      - data_process.contamination
    outs:
      - data/processed
      - src/visualization

  feature_engineering:
    cmd: python src/feature_engineering.py
    deps:
      - src/feature_engineering.py
      - data/processed
    params:
      - base.target_col
    outs:
      - data/featured

  train_model:
    cmd: python src/train_data.py
    deps:
      - src/train_data.py
      - data/featured
    params:
      - base
      - train
      - baseline_params
    # No .joblib output file here, as it's tracked by MLflow

  evaluate_model:
    cmd: python src/test_data.py
    deps:
      - src/test_data.py
      - data/featured
    params:
      - base.target_col
      - train.model_name
      - evaluate.predictions_csv
    outs:
      - data/results/predictions.csv